{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Zz9PJeMgfjYr"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9voP6lvfnK5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/new_paper/ACDC\n","%run otherUnets.ipynb\n","%run preprocessing_2D.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hHG4otOKfWaR","executionInfo":{"status":"ok","timestamp":1638372402634,"user_tz":-420,"elapsed":13268,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"bd103571-8057-4849-f19d-1844174fc8ba"},"source":["!pip install pytorch-lightning\n","import pytorch_lightning as pl\n","from IPython.display import clear_output\n","import nibabel as nib\n","import csv\n","import os\n","import glob\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","from fastprogress import master_bar, progress_bar\n","from torchvision import transforms\n","import torch.optim as optim\n","from itertools import product\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader,Dataset\n","import matplotlib.pyplot as plt\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","class HistoryLogger(pl.callbacks.Callback):\n","    def __init__(self, dir = \"history_acdcUnet_CE.csv\"):\n","        self.dir = dir\n","    def on_validation_epoch_end(self, trainer, pl_module):\n","        metrics = trainer.callback_metrics\n","        if \"loss_epoch\" in metrics.keys():\n","            logs = {\"epoch\": trainer.current_epoch}\n","            keys = [\"loss_epoch\", \"train_diceRV_epoch\", \"train_diceMYO_epoch\",\n","                    \"train_diceLV_epoch\", \"val_loss\",\"val_diceRV\", \"val_diceMYO\", \"val_diceLV\"\n","                    ]\n","            for key in keys:\n","                logs[key] = metrics[key].item()\n","            header = list(logs.keys())\n","            isFile = os.path.isfile(self.dir)\n","            with open(self.dir, 'a', newline='') as csvfile:\n","                writer = csv.DictWriter(csvfile, fieldnames=header)\n","                if not isFile:\n","                    writer.writeheader()\n","                writer.writerow(logs)\n","        else:\n","            pass\n","def setDropProb(model, prob=0.01):\n","    for layer in model.modules():\n","        if isinstance(layer, DropBlock2D):\n","            layer.drop_prob = prob\n","clear_output()\n","############## turn off Debug APIs for Final Training############\n","torch.autograd.set_detect_anomaly(False)\n","torch.autograd.profiler.profile(False)\n","torch.autograd.profiler.emit_nvtx(False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.profiler.emit_nvtx at 0x7fd2a4e3bdd0>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"KP7xIbNvQNlz"},"source":["data = np.load(\"./dataACDCA/ACDC_train_aug160.npz\")\n","x_train, y_train = data[\"image\"], data[\"mask\"]\n","data = np.load(\"./dataACDCA/ACDC_val160.npz\")\n","x_val, y_val = data[\"image\"], data[\"mask\"]\n","data = np.load(\"./dataACDCA/ACDC_test160.npz\")\n","x_test, y_test = data[\"image\"], data[\"mask\"]\n","del data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rvRg5bzfeM3"},"source":["train_dataset = DataLoader(ACDCLoader(x_train, y_train, transform=False), batch_size=16, pin_memory=True,\n","                        shuffle=True, num_workers=2,\n","                        drop_last=True, prefetch_factor = 16)\n","val_dataset = DataLoader(ACDCLoader(x_val, y_val, typeData=\"test\"), batch_size=64,\n","                          num_workers=2, prefetch_factor=64)\n","test_dataset = DataLoader(ACDCLoader(x_test, y_test, typeData=\"test\"), batch_size=64,\n","                          num_workers=2, prefetch_factor=64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQntyQF4gUsn"},"source":["class Segmentor(pl.LightningModule):\n","    def __init__(self, model = U_Net(drop_prob=0)):\n","        super().__init__()\n","        self.model = model\n","    def forward(self, x):\n","        return self.model(x)\n","    def get_metrics(self):\n","        # don't show the version number\n","        items = super().get_metrics()\n","        items.pop(\"v_num\", None)\n","        return items\n","\n","    # def _step(self, batch):\n","    #     image, y_true = batch\n","    #     y_pred = self.model(image)\n","    #     loss = SemiActiveLoss(device=self.device)(image, y_true, y_pred)\n","    #     diceRV, diceMYO, diceLV = dice_rv(y_true, y_pred), dice_myo(y_true, y_pred), dice_lv(y_true, y_pred)\n","    #     return loss, diceRV, diceMYO, diceLV\n","    def _step(self, batch):\n","        image, y_true = batch\n","        y_pred = self.model(image)\n","        loss = CrossEntropy(device=self.device)( y_true, y_pred)\n","        diceRV, diceMYO, diceLV = dice_rv(y_true, y_pred), dice_myo(y_true, y_pred), dice_lv(y_true, y_pred)\n","        return loss, diceRV, diceMYO, diceLV\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, diceRV, diceMYO, diceLV = self._step(batch)\n","        metrics = {\"loss\": loss, \"train_diceRV\": diceRV, \"train_diceMYO\": diceMYO, \"train_diceLV\": diceLV}\n","        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar = True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, diceRV, diceMYO, diceLV = self._step(batch)\n","        metrics = {\"val_loss\": loss, \"val_diceRV\": diceRV, \"val_diceMYO\": diceMYO, \"val_diceLV\": diceLV}\n","        self.log_dict(metrics, prog_bar = True)\n","        return metrics\n","\n","    def test_step(self, batch, batch_idx):\n","        loss, diceRV, diceMYO, diceLV = self._step(batch)\n","        metrics = {\"test_diceRV\": diceRV, \"test_diceMYO\": diceMYO, \"test_diceLV\": diceLV}\n","        self.log_dict(metrics, prog_bar = True)\n","        return metrics\n","\n","\n","    def configure_optimizers(self):\n","        optimizer = Nadam(self.parameters(), lr=1e-3)\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\",\n","                                                         factor = 0.5, patience=15, verbose =True)\n","        lr_schedulers = {\"scheduler\": scheduler, \"monitor\": \"val_diceRV\"}\n","        return [optimizer], lr_schedulers\n",""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yGvwcvogemW"},"source":["segmentor = Segmentor(U_Net(drop_prob=0))\n","check_point = pl.callbacks.model_checkpoint.ModelCheckpoint(\"./weightUnet/\", filename=\"ckpt{val_diceRV:0.4f}\",\n","                                                            monitor=\"val_diceRV\", mode = \"max\", save_top_k =5,\n","                                                            verbose=True, save_weights_only=True,\n","                                                            auto_insert_metric_name=False,)\n","progress_bar = pl.callbacks.TQDMProgressBar()\n","logger = HistoryLogger()\n","swa = pl.callbacks.StochasticWeightAveraging(swa_epoch_start=25)\n","PARAMS = {\"gpus\":1, \"benchmark\": True, \"enable_progress_bar\" : False, \"logger\":False,\n","        #   \"callbacks\" : [progress_bar],\n","        #    \"overfit_batches\" :1,\n","          \"callbacks\" : [check_point, progress_bar, logger],\n","          \"log_every_n_steps\" :1, \"num_sanity_val_steps\":1, \"max_epochs\":5,\n","          \"precision\":16,\n","          }\n","\n","trainer = pl.Trainer(**PARAMS)\n","# segmentor = Segmentor.load_from_checkpoint(checkpoint_path=\"./weightUnet/ckpt0.7439.ckpt\")\n","# segmentor = Segmentor.load_from_checkpoint(checkpoint_path=\"./weightUnet/current.ckpt\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfZD1VM_Xrn-"},"source":["trainer.fit(segmentor, train_dataset, val_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIrezIVOz6d0"},"source":["# for drop_prob in np.linspace(0.01, 0.1, 10):\n","#     setDropProb(segmentor, drop_prob)\n","#     trainer = pl.Trainer(**PARAMS)\n","#     trainer.fit(segmentor, train_dataset, val_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5Ix4aD35HsC"},"source":["trainer.save_checkpoint(\"./weightUnet/current.ckpt\", weights_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eds9aXuwkeni","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638226660378,"user_tz":-420,"elapsed":333,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"7cf40224-1dea-4b8e-bdc4-6e89680d330a"},"source":["for layer in segmentor.modules():\n","    if isinstance(layer, DropBlock2D):\n","        layer.drop_prob = 0.1\n","\n","for layer in segmentor.modules():\n","    if isinstance(layer, DropBlock2D):\n","        print(layer.drop_prob)\n","\n","# segmentor.configure_optimizers()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.1\n","0.1\n"]}]},{"cell_type":"code","metadata":{"id":"JyS8MDjazAWV"},"source":["trainer.test(segmentor, val_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8H03s0wiHIgU"},"source":["def predict(images, model, batch_size = 64):\n","    images = torch.as_tensor(images, dtype= torch.float32)\n","    y_preds = torch.zeros((images.size(0), NUM_CLASS, images.size(2), images.size(3)), device= device)\n","    batch_start = 0\n","    batch_end = batch_size\n","    pbar = tqdm()\n","    while batch_start < images.size(0):\n","        image = images[batch_start : batch_end]\n","        with torch.inference_mode():\n","            image = image.to(device)\n","            y_pred = model(image)\n","            y_preds[batch_start : batch_end] = y_pred\n","        batch_start += batch_size\n","        batch_end += batch_size\n","        pbar.update(1)\n","    pbar.close()\n","    res = y_preds.cpu().numpy()\n","    del y_preds\n","    return res\n","def dice_volume_rv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = torch.where(y_pred == 1, 1, 0)\n","    y_true = torch.where(y_true == 1, 1, 0)\n","    intersection = torch.sum(y_true * y_pred)\n","    cardinality  = torch.sum(y_true + y_pred)\n","    return (2. * intersection + smooth) / (cardinality + smooth)\n","\n","def dice_volume_myo(y_true, y_pred, smooth = 1e-5):\n","    y_pred = torch.where(y_pred == 2, 1, 0)\n","    y_true = torch.where(y_true == 2, 1, 0)\n","    intersection = torch.sum(y_true * y_pred)\n","    cardinality  = torch.sum(y_true + y_pred)\n","    return (2. * intersection + smooth) / (cardinality + smooth)\n","\n","def dice_volume_lv(y_true, y_pred, smooth = 1e-5):\n","    y_pred = torch.where(y_pred == 3, 1, 0)\n","    y_true = torch.where(y_true == 3, 1, 0)\n","    intersection = torch.sum(y_true * y_pred)\n","    cardinality  = torch.sum(y_true + y_pred)\n","    return (2. * intersection + smooth) / (cardinality + smooth)\n","\n","def predict_volume(images, model, batch_size = 64):\n","    images = torch.as_tensor(images, dtype= torch.float32)\n","    y_preds = torch.zeros((images.size(0), NUM_CLASS, images.size(2), images.size(3)), device= device)\n","    batch_start = 0\n","    batch_end = batch_size\n","    while batch_start < images.size(0):\n","        image = images[batch_start : batch_end]\n","        with torch.inference_mode():\n","            image = image.to(device)\n","            y_pred = model(image)\n","            y_preds[batch_start : batch_end] = y_pred\n","        batch_start += batch_size\n","        batch_end += batch_size\n","    res = y_preds.cpu().numpy()\n","    del y_preds\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qw30lMgYmeSR"},"source":["\n","weight_path = sorted(glob.glob(\"./weightUnet/*\"), reverse=True)\n","weight_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWqm1ToM5xGW"},"source":["all_files = sorted(glob.glob(\"./dataACDCA/training/*\"))\n","np.random.seed(42)\n","np.random.shuffle(all_files)\n","train_count = 70\n","train_files = all_files[:train_count]\n","test_files = all_files[train_count : train_count + 10]+all_files[-10:]\n","valid_files = all_files[train_count + 10: train_count + 20]\n","x_inf = np.zeros((x_test.shape[0], 1, x_test.shape[1], x_test.shape[2]))\n","for i in range(x_test.shape[0]):\n","    x_inf[i, 0] = min_max_preprocess(x_test[i])\n","\n","weight_path = sorted(glob.glob(\"./weightUnet/*\"), reverse=True)\n","max_score = 0\n","best_weight = \"\"\n","# weight_path = [\"./weights/ckpt0.8288.ckpt\"]\n","for weight in tqdm(weight_path):\n","    segmentor = Segmentor.load_from_checkpoint(checkpoint_path=weight)\n","    segmentor = segmentor.to(device)\n","    segmentor.eval()\n","    y_pred = predict_volume(x_inf, segmentor)\n","    torch.cuda.empty_cache()\n","    mask_predict = np.argmax(y_pred, axis=1)\n","    count = 0\n","    list_rv, list_myo, list_lv = [], [], []\n","    for files in test_files:\n","        list_image = [x for x in glob.glob(files+\"/*\") if x.find('frame') != -1 and x.find('gt') == -1]\n","        for image_name in list_image:\n","            num = image_name.find(\"nii\")\n","            mask_name = image_name[:num-1] +\"_gt.nii.gz\"\n","            image = nib.load(image_name).get_fdata().astype(np.uint16)\n","            label = nib.load(mask_name).get_fdata().astype(np.uint8)\n","            image = center_crop(image)\n","            label = center_crop(label)\n","            label_pred = np.zeros_like(label)\n","            for z in range(label.shape[-1]):\n","                label_pred[..., z] = mask_predict[count]\n","                count += 1\n","            label = torch.from_numpy(label)\n","            label_pred = torch.from_numpy(label_pred)\n","            list_rv.append(dice_volume_rv(label, label_pred).item())\n","            list_myo.append(dice_volume_myo(label, label_pred).item())\n","            list_lv.append(dice_volume_lv(label, label_pred).item())\n","    diceRV = np.mean(list_rv)\n","    diceMYO = np.mean(list_myo)\n","    diceLV = np.mean(list_lv)\n","    dice_ave = np.mean([diceRV, diceMYO, diceLV])\n","    clear_output()\n","    print(dice_ave)\n","    if max_score < dice_ave:\n","        max_score = dice_ave\n","        best_weight = weight\n","print(f\"best weight is: {best_weight} with {max_score}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8By3ARB_6oF2","executionInfo":{"status":"ok","timestamp":1638374352169,"user_tz":-420,"elapsed":392,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"0737b7f7-f1c7-492b-ab53-8481e0f17441"},"source":["print(diceRV, diceMYO, diceLV, np.mean([diceRV, diceMYO, diceLV]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8687375321984291 0.8820093542337417 0.9281433686614037 0.8929634183645248\n"]}]},{"cell_type":"code","metadata":{"id":"xKk6u5ZDbkEY"},"source":[],"execution_count":null,"outputs":[]}]}