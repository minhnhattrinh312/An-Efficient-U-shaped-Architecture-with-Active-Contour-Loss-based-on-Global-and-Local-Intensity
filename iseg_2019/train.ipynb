{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nn-qM3LsJCis","executionInfo":{"status":"ok","timestamp":1631852384665,"user_tz":-420,"elapsed":23,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05773131169689709632"}},"outputId":"22559438-98cc-4d37-d2c5-cca9901348b8"},"source":["!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-30957238-4214-7a84-2636-ae83fae7f03d)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Izv8OjTgKfV8","executionInfo":{"status":"ok","timestamp":1631852445399,"user_tz":-420,"elapsed":18077,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05773131169689709632"}},"outputId":"ff146d4d-1476-4bb0-e41a-1e0a7e2296e2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"xs6nunNwJIvB"},"source":["import zipfile\n","with zipfile.ZipFile(\"/content/drive/MyDrive/iseg2019/dataISEG_np/train_patch32_stride8.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"data_train\")\n","with zipfile.ZipFile(\"/content/drive/MyDrive/iseg2019/dataISEG_np/test_patch32_stride8.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"data_test\")\n","# with zipfile.ZipFile(\"/content/drive/MyDrive/iseg2019/dataISEG_np/pseudo_data.zip\", 'r') as zip_ref:\n","#     zip_ref.extractall(\"pseudo_data\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4peVAgmCJXZi"},"source":["%cd /content/drive/MyDrive/iseg2019/\n","%run Unet.ipynb\n","%run data_preprocessing.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmHc63BbJY-E"},"source":["# !pip install volumentations-3D\n","# from volumentations import *\n","# !pip install imjoy scikit-image\n","#https://github.com/ZFTurbo/volumentations/blob/4e2c73add77d7fdbc5f69d4248c893f6e6aa67dc/volumentations/augmentations/transforms.py#L154\n","import gc\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.models import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.layers import *\n","import keras.backend as K\n","from itertools import product\n","import os\n","import scipy.io as sio\n","from scipy import ndimage\n","import matplotlib.pyplot as plt\n","import tensorflow_probability as tfp\n","from tqdm import tqdm\n","from fastprogress import master_bar, progress_bar\n","import nibabel as nib\n","import glob \n","!pip install keras-swa\n","from swa.tfkeras import SWA\n","from mpl_toolkits import mplot3d\n","from IPython.display import clear_output\n","from keras.utils import np_utils\n","from sklearn.feature_extraction.image import extract_patches as sk_extract_patches\n","from sklearn.model_selection import train_test_split\n","from skimage import exposure\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F0DXvDSBaupX"},"source":["##train"]},{"cell_type":"code","metadata":{"id":"Q6x52-l4Jr-T"},"source":["def gradientLoss(y_pred,penalty = \"l1\"):\n","\n","    dH = tf.math.abs(y_pred[:,1:,...] - y_pred[:,:-1,...])\n","    dW = tf.math.abs(y_pred[:,:,1:,...] - y_pred[:,:,:-1,...])\n","    dD = tf.math.abs(y_pred[...,1:,:] - y_pred[...,:-1,:])\n","    if penalty == \"l2\":\n","        dH = dH * dH\n","        dW = dW * dW\n","        dD = dD * dD\n","\n","    loss =  tf.reduce_sum(dH) +  tf.reduce_sum(dW)+ tf.reduce_sum(dD)\n","    return loss\n","def gaussian_kernel(kernel_size: int, mean: float, std: float):\n","    \"\"\"Makes 3D gaussian Kernel for convolution.\"\"\"\n","    d = tfp.distributions.Normal(mean, std)\n","    vals = d.prob(tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0))\n","    gauss_kernel = tf.einsum('i,j,k->ijk', vals, vals,vals)\n","    gauss_kernel = gauss_kernel / tf.reduce_sum(gauss_kernel)\n","    gauss_kernel = gauss_kernel[...,tf.newaxis, tf.newaxis]\n","    return gauss_kernel\n","\n","def levelsetLoss(y_true, y_pred, kernel_size=5, mean_kernel=0, std_kernel=5):\n","    kernel = gaussian_kernel(kernel_size, mean_kernel, std_kernel)\n","    kernel = tf.repeat(kernel, y_pred.shape[-1], axis = -1)u\n","    lossRegion = 0.0\n","    y_pred_fuzzy = y_pred ** 2\n","    for ich in range(2):\n","        target_ = y_true[...,ich:ich+1]   \n","        pcentroid_1_local = tf.nn.conv3d(target_ * y_pred_fuzzy + 1e-6, kernel, strides=[1,1,1,1,1], padding='SAME')\n","        pcentroid_2_local =  tf.nn.conv3d(y_pred_fuzzy + 1e-6, kernel, strides=[1,1,1,1,1], padding='SAME')\n","        pcentroid_local = pcentroid_1_local / pcentroid_2_local\n","        plevel_local = target_ - pcentroid_local\n","        loss_local = plevel_local * plevel_local * y_pred_fuzzy\n","\n","        pcentroid_global = tf.reduce_sum(target_ * y_pred_fuzzy, (1,2,3),keepdims=True)\\\n","                    /tf.reduce_sum(y_pred_fuzzy+1e-6, (1,2,3),keepdims = True)   \n","        plevel_global = target_ - pcentroid_global\n","        loss_global = plevel_global * plevel_global * y_pred_fuzzy\n","\n","        lossRegion += tf.reduce_sum(loss_local)+tf.reduce_sum(loss_global)\n","\n","    return lossRegion \n","\n","def lossGlobalAndLocal(y_true, y_pred, beta = 1e-3):\n","    lossLevelset = levelsetLoss(y_true, y_pred)\n","    lossLength = gradientLoss(y_pred)\n","\n","    return lossLevelset + beta * lossLength\n","\n","def ActiveContourLoss(y_true, y_pred, smooth=1e-5):   \n","    axes = (1,2,3,4)\n","    yTrueOnehot = tf.one_hot(tf.squeeze(y_true,axis=-1), depth = NUM_CLASS)[...,1:]\n","    #this is Luac:\n","    y_pred = y_pred[...,1:]\n","\n","    active = -tf.cast(tf.math.log(1-y_pred+smooth),tf.float32) * (1-yTrueOnehot) - tf.cast(tf.math.log(y_pred+smooth),tf.float32)*yTrueOnehot\n","    loss = tf.reduce_sum(active, axis = axes) / tf.reduce_sum(yTrueOnehot + y_pred-yTrueOnehot*y_pred+smooth, axis = axes)\n","    return tf.reduce_mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9xvBLMHJr78"},"source":["mcp = ModelCheckpoint(\"./train_noPseudo/ckpt{val_active_dice_WM:.4f}.h5\",mode='max',monitor='val_active_dice_WM',verbose=1,\n","                      save_best_only=True, save_weights_only=True)\n","earlystop= EarlyStopping(monitor='val_active_dice_WM',patience=150,mode='max',verbose=1)\n","rlr = ReduceLROnPlateau(monitor='val_active_dice_WM', factor=0.7, mode='max', patience=20, min_lr=1e-7, verbose=1)\n","csv_logger = CSVLogger(\"history.csv\",append= True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsVrBGgd9DXI"},"source":["def IsegLoader(typeData = \"train\", train_path=TRAIN_PATH, test_path= TEST_PATH, \n","               shuffle=True, augment=False):\n","    list_testName = sorted(glob.glob(test_path))\n","    listName =  glob.glob(train_path) + glob.glob(PSEUDO_PATH) if typeData == \"train\" else list_testName\n","    augment =  augment if typeData == \"train\" else False  # augment data bool\n","    indexes = np.arange(len(listName))\n","    if shuffle and typeData == \"train\":\n","        np.random.shuffle(indexes)   \n","    for i in indexes:\n","        subject = np.load(listName[i])\n","        volume, mask = subject[\"image\"], subject[\"mask\"]\n","    ####################### augmentation data ##############################\n","        # if augment:\n","        #     volume = gen_augmentation(volume)\n","        yield {\"inputs\": volume}, {\"active\": mask, \"levelset\": volume}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5HO4g96b9_T"},"source":["train_dataset = tf.data.Dataset.from_generator(IsegLoader, \n","                                               output_types=({\"inputs\": tf.float32}, {\"active\": tf.uint8, \"levelset\": tf.float32}))\n","train_dataset  = train_dataset.batch(16, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n","\n","test_dataset = tf.data.Dataset.from_generator(IsegLoader, args=[\"test\"],\n","                                              output_types=({\"inputs\": tf.float32}, {\"active\": tf.uint8, \"levelset\": tf.float32}))\n","test_dataset  = test_dataset.batch(64).prefetch(tf.data.AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ev6qEBWQPNfC"},"source":["# S.load_weights(\"./train_noPseudo/ckpt0.9217.h5\")\n","# for keep_prob in np.linspace(start = 0.96, stop = 0.95, num=2):\n","#     print(\"dropout rate is:\", keep_prob)\n","#     new_model = seg_net(keep_prob = keep_prob)\n","#     new_model.set_weights(S.get_weights())\n","#     S = new_model\n","#     S.compile(optimizer=Nadam(learning_rate=7e-4), loss={\"active\":ActiveContourLoss, \n","#                                                             \"levelset\":lossGlobalAndLocal},\\\n","#             loss_weights={\"active\": 1.0, \"levelset\": 1e-8},\\\n","#             metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})\n","#     S.fit(train_dataset,epochs = 1, callbacks=[mcp, rlr,earlystop,csv_logger],\\\n","#           validation_data=test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7A-1QZI4Fl_t"},"source":["S = seg_net(keep_prob= 0.95)\n","S.compile(optimizer=Nadam(learning_rate=3e-4), loss={\"active\":ActiveContourLoss, \n","                                                        \"levelset\":lossGlobalAndLocal},\\\n","        loss_weights={\"active\": 1.0, \"levelset\": 1e-8},\\\n","        metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kI4KoD_vHfX"},"source":["# swa = SWA(start_epoch=2, \n","#           lr_schedule=\"manual\", \n","#         #   swa_lr=2e-5,\n","#         #   swa_lr2=0.001,\n","#         #   swa_freq=2,\n","#           batch_size=16,# needed when using batch norm\n","#           verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1HncFcxKk10"},"source":["S.load_weights(\"./train_noPseudo/ckpt0.9773.h5\")\n","S.compile(optimizer=Nadam(learning_rate=2e-4), loss={\"active\":ActiveContourLoss, \n","                                                        \"levelset\":lossGlobalAndLocal},\\\n","        loss_weights={\"active\": 1.0, \"levelset\": 1e-8},\\\n","        metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MY8nGx5SB5hw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd8be916-7480-4ac1-b548-4f4ef3fd0468"},"source":["S.fit(train_dataset,epochs = 1000, callbacks=[mcp, rlr,earlystop,csv_logger], \\\n","      validation_data=test_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","2233/2233 [==============================] - 3721s 2s/step - loss: 0.0615 - active_loss: 0.0614 - levelset_loss: 10571.8096 - active_dice_CSF: 0.9892 - active_dice_GM: 0.9850 - active_dice_WM: 0.9755 - val_loss: 0.0564 - val_active_loss: 0.0560 - val_levelset_loss: 42108.9883 - val_active_dice_CSF: 0.9909 - val_active_dice_GM: 0.9852 - val_active_dice_WM: 0.9782\n","\n","Epoch 00001: val_active_dice_WM improved from 0.97650 to 0.97822, saving model to ./train_noPseudo/ckpt0.9782.h5\n","Epoch 2/1000\n"," 620/2233 [=======>......................] - ETA: 42:11 - loss: 0.0604 - active_loss: 0.0603 - levelset_loss: 10599.2275 - active_dice_CSF: 0.9895 - active_dice_GM: 0.9852 - active_dice_WM: 0.9761"]}]},{"cell_type":"code","metadata":{"id":"ug3QTfFbx7d-"},"source":["# S.load_weights(\"./train_noPseudo/weightSWA.h5\")\n","S.evaluate(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bw1EkJDzJxOi"},"source":["# if isinstance(layer, DropBlock3D):\n","#         print(layer.block_size)\n","# S = load_model(\"model_U_Unet.h5\",\n","#                custom_objects={\"Swish\":Swish,\"DropBlock3D\":DropBlock3D}, compile=False)\n","# S.compile(optimizer=Nadam(learning_rate=1.25e-4), loss={\"active\":ActiveContourLoss, \n","#                                                         \"levelset\":levelsetLossCVES},\\\n","#         loss_weights={\"active\": 1.0, \"levelset\": 1e-9},\\\n","#         metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})\n","# S.evaluate(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CdehVOL0NwYM"},"source":["##psedo labeling\n"]},{"cell_type":"code","metadata":{"id":"V04xssgQN1PD"},"source":["def getValidIndex(label_constructed, patchT1, threshold):\n","    filter = np.max(label_constructed, axis=-1,keepdims=True)\n","    patch = extract_patches(filter, PATCH_SIZE, EXTRACTION_STEP)\n","    valid_index = []\n","    for index in range(patch.shape[0]):\n","        if (not False in np.unique(patch[index] > threshold)) and np.sum(patchT1[index]) != 0:\n","            valid_index.append(index)\n","    return valid_index\n","# IMG_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Validation/\"\n","# LABEL_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2017-Test-Prob/\"\n","# for i in range(11,24):\n","#     print(\"\\rsegment : {}th subject\".format(i), end=\"\")\n","#     imgT1 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","#     imgT1 = normalize(imgT1)\n","#     imgT2 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","#     imgT2 = normalize(imgT2)\n","#     patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","#     patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","\n","#     pred = np.zeros((*patchT1.shape[:-1], NUM_CLASS))\n","#     pred[...,0] = 1\n","#     valid_index = np.where(np.sum(patchT1, axis=(1, 2, 3, 4)) != 0)\n","#     patchT1_valid = tf.convert_to_tensor(patchT1[valid_index], tf.float32)\n","#     patchT2_valid = tf.convert_to_tensor(patchT2[valid_index], tf.float32)\n","#     del patchT1, patchT2\n","#     temp = S.predict({\"inputT1\": patchT1_valid, \n","#                         \"inputT2\": patchT2_valid}, batch_size = 64)[0]\n","#     gc.collect()\n","#     K.clear_session()\n","#     pred[valid_index] = temp\n","#     del valid_index, temp, patchT1_valid, patchT2_valid\n","#     label_constructed = reconstruct_volume_avg(pred, imgT1.shape[:-1], EXTRACTION_STEP)\n","#     del imgT1, imgT2, pred\n","#     label_save = nib.Nifti1Image(label_constructed, np.eye(4))\n","#     nib.save(label_save, LABEL_SUBMIT_PATH+\"subject-\"+str(i)+\"-label.nii.gz\")    \n","#     del label_constructed, label_save\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOFR6k56kruh"},"source":["# count_train = 1\n","# PSEUDO_PATH = \"/content/pseudo_data/\"\n","# GET_LABEL_PATH  = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2017-Test-Prob/\"\n","# GET_IMAGE_PATH  = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2017-Testing/\"\n","# for i in range(11, 24):\n","#     label_constructed = nib.load(GET_LABEL_PATH+\"subject-\"+str(i)+\"-label.nii.gz\").get_fdata()\n","#     imgT1 = nib.load(GET_IMAGE_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","#     imgT1 = normalize(imgT1)\n","#     patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","#     valid_index = getValidIndex(label_constructed, patchT1, 0.5)\n","\n","#     x_t1 = patchT1[valid_index]\n","#     del patchT1, imgT1\n","#     output_standard = np.expand_dims(np.argmax(label_constructed, axis=-1), axis=-1)\n","#     label_patch = extract_patches(output_standard,PATCH_SIZE,EXTRACTION_STEP)\n","#     label = label_patch[valid_index]\n","#     del label_patch, output_standard, label_constructed\n","#     imgT2 = nib.load(GET_IMAGE_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","#     imgT2 = normalize(imgT2)\n","#     patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","#     x_t2 = patchT2[valid_index]\n","#     del patchT2, imgT2 \n","\n","#     for j in range(len(valid_index)):\n","#         print(\"\\rsave \",count_train,\"th volume for train\", end=\"\")             \n","#         imgT1 = nib.Nifti1Image( x_t1[j], np.eye(4))\n","#         nib.save(imgT1, PSEUDO_PATH+ 'T1_train_'+str(count_train)+'.nii.gz')  \n","#         imgT2 = nib.Nifti1Image( x_t2[j], np.eye(4))\n","#         nib.save(imgT2, PSEUDO_PATH+ 'T2_train_'+str(count_train)+'.nii.gz')  \n","#         img_mask = nib.Nifti1Image(label[j], np.eye(4))\n","#         nib.save(img_mask, PSEUDO_PATH+'mask_train_'+str(count_train)+'.nii.gz')    \n","#         count_train += 1 \n","# import shutil\n","# shutil.make_archive(\"/content/drive/MyDrive/iseg2019/pseudo_data\", \"zip\",\"/content/pseudo_data\") "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tJeH2AGxNt_T"},"source":["##submit"]},{"cell_type":"code","metadata":{"id":"o46F03DFsFlQ"},"source":["S.inputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aY8GR_dPq-hB"},"source":["def convertLable2Submit(label):\n","    class_mapper_inv = {1 : 10, 2 : 150, 3 : 250}\n","    for key, value in class_mapper_inv.items():\n","        label = np.where(label==key, value, label)\n","    return label.astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5t4-nDMNKCjY"},"source":["S = load_model(\"model_U_Unet.h5\",\n","               custom_objects={\"Swish\":Swish,\"DropBlock3D\":DropBlock3D}, compile=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNhZbMW7Q6Os"},"source":["# dice_csf = []\n","# dice_gm = []\n","# dice_wm = []\n","# for j in range(1,3):\n","#     imgT1 = nib.load(\"./dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-T1.hdr\").get_fdata()\n","#     imgT1 = min_max_preprocess(imgT1)\n","#     imgT2 = nib.load(\"./dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-T2.hdr\").get_fdata()\n","#     imgT2 = min_max_preprocess(imgT2)\n","#     label = nib.load(\"./dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-label.hdr\").get_fdata()\n","    # del imgT1, imgT2\n","#     inputs = np.concatenate([imgT1, imgT2], axis= -1)\n","#     input_patches = extract_patches(inputs, PATCH_SIZE, EXTRACTION_STEP)\n","#     input_patches = tf.convert_to_tensor(input_patches, tf.float32)\n","\n","#     pred = S.predict(input_patches, batch_size = 64)[0]\n","#     del input_patches\n","#     gc.collect()\n","#     K.clear_session()\n","#     label_constructed = reconstruct_volume_avg(pred, inputs.shape[:-1], EXTRACTION_STEP)\n","#     del pred\n","#     output_standard = tf.expand_dims(tf.argmax(label_constructed,axis=-1), axis=-1)\n","#     del label_constructed\n","#     for i in range(1,4):\n","#         output_CSF = np.where(output_standard == i, 1.0, 0.0)\n","#         label_CSF = np.where(label == i, 1.0, 0.0)\n","\n","#         intersection = K.sum(label_CSF * output_CSF, axis=[0,1,2,3])\n","#         union = K.sum(label_CSF, axis=[0,1,2,3]) + K.sum(output_CSF, axis=[0,1,2,3])\n","#         dice = ((2. * intersection + 1) / (union + 1))\n","#         if i==1:\n","#             dice_csf.append(dice)\n","#         elif i==2:\n","#             dice_gm.append(dice)\n","#         else : \n","#             dice_wm.append(dice)\n","#         print(f\"subject {j}: \", dice)\n","#     del intersection, union, dice, label, output_standard     \n","# print(np.mean(dice_csf), np.mean(dice_gm),np.mean(dice_wm))                    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QORzoxVFLeih"},"source":["IMG_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Validation/\"\n","LABEL_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Validation-Label/\"\n","for i in range(11,24):\n","    print(\"\\rsegment : {}th subject\".format(i), end=\"\")\n","    affine = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T1.hdr\").affine\n","    imgT1 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","    imgT1 = min_max_preprocess(imgT1)\n","    imgT2 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","    imgT2 = min_max_preprocess(imgT2)\n","\n","    inputs = np.concatenate([imgT1, imgT2], axis= -1)\n","    del imgT1, imgT2\n","    input_patches = extract_patches(inputs, PATCH_SIZE, EXTRACTION_STEP)\n","    input_patches = tf.convert_to_tensor(input_patches, tf.float32)\n","\n","    pred = S.predict(input_patches, batch_size = 64)[0]\n","    del input_patches\n","    gc.collect()\n","    K.clear_session()\n","    label_constructed = reconstruct_volume_avg(pred, inputs.shape[:-1], EXTRACTION_STEP)\n","    del pred\n","    output_standard = tf.expand_dims(tf.argmax(label_constructed,axis=-1), axis=-1)\n","    del label_constructed\n","\n","    label_save = nib.Nifti1Image(output_standard,affine)\n","    nib.nifti1.save(label_save, LABEL_SUBMIT_PATH+\"subject-\"+str(i)+\"-label.hdr\")\n","    del output_standard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bbg9-epxS_jx"},"source":["IMG_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Validation/\"\n","LABEL_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Validation-Label/\"\n","for i in range(11,24):\n","    print(\"\\rsegment : {}th subject\".format(i), end=\"\")\n","    imgT1 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","    imgT1 = normalize(imgT1)\n","    imgT2 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","    imgT2 = normalize(imgT2)\n","    patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","    patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","\n","    pred = np.zeros((*patchT1.shape[:-1], NUM_CLASS))\n","    pred[...,0] = 1\n","    valid_index = np.where(np.sum(patchT1, axis=(1, 2, 3, 4)) != 0)\n","    patchT1_valid = tf.convert_to_tensor(patchT1[valid_index], tf.float32)\n","    patchT2_valid = tf.convert_to_tensor(patchT2[valid_index], tf.float32)\n","    del patchT1, patchT2\n","    temp = S.predict({\"inputT1\": patchT1_valid, \n","                        \"inputT2\": patchT2_valid}, batch_size = 32)[0]\n","    gc.collect()\n","    K.clear_session()\n","    pred[valid_index] = temp\n","    del valid_index, temp, patchT1_valid, patchT2_valid\n","    label_constructed = reconstruct_volume_avg(pred, imgT1.shape[:-1], EXTRACTION_STEP)\n","    output_standard = np.expand_dims(np.argmax(label_constructed, axis=-1), axis=-1).astype(np.uint8)\n","    del imgT1, imgT2, pred, label_constructed\n","\n","    label_save = nib.Nifti1Image(output_standard, np.eye(4))\n","    nib.nifti1.save(label_save, LABEL_SUBMIT_PATH+\"subject-\"+str(i)+\"-label.hdr\")\n","    del output_standard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LDi5lZfKHwk"},"source":["IMG_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Testing/\"\n","LABEL_SUBMIT_PATH = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Test-label/\"\n","for i in range(24,40):\n","    print(\"\\rsegment : {}th subject\".format(i), end=\"\")\n","    imgT1 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","    imgT1 = normalize(imgT1)\n","    imgT2 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","    imgT2 = normalize(imgT2)\n","    patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","    patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","    pred = np.zeros((*patchT1.shape[:-1], NUM_CLASS))\n","    valid_index = np.where(np.sum(patchT1, axis=(1, 2, 3, 4)) != 0)\n","    pred[valid_index] = S.predict({\"inputT1\": patchT1[valid_index],\"inputT2\": patchT2[valid_index]})[0]\n","    label_constructed = reconstruct_volume_avg(pred, imgT1.shape[:-1], EXTRACTION_STEP)\n","    output_standard = np.expand_dims(np.argmax(label_constructed, axis=-1), axis=-1).astype(np.uint8)\n","\n","    label_save = nib.Nifti1Image(output_standard, np.eye(4))\n","    nib.nifti1.save(label_save, LABEL_SUBMIT_PATH+\"subject-\"+str(i)+\"-label.hdr\")\n","    del imgT1, imgT2, patchT1, patchT2, pred, label_constructed, output_standard,label_save,valid_index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibS9jMLKKI_6"},"source":["j = 1\n","imgT1 = nib.load(\"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-T1.hdr\").get_fdata()\n","imgT1 = normalize(imgT1)\n","imgT2 = nib.load(\"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-T2.hdr\").get_fdata()\n","imgT2 = normalize(imgT2)\n","label = nib.load(\"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-label.hdr\").get_fdata()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4umTGksTZLyg"},"source":["imgT1 = nib.load(\"/content/pseudo_data/T1_train_2000.nii.gz\").get_fdata()\n","imgT2 = nib.load(\"/content/pseudo_data/T2_train_2000.nii.gz\").get_fdata()\n","label = nib.load(\"/content/pseudo_data/mask_train_2001.nii.gz\").get_fdata()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1hdDAF4bMRm"},"source":["np.unique(label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cq4WmSY_KKEd"},"source":["for i in range(32):\n","    plt.figure(i+1, figsize=(24,24))\n","    plt.subplot(131),plt.imshow(imgT1[:,:,i,0]),plt.title('T1')\n","    plt.subplot(132),plt.imshow(imgT2[:,:,i,0]),plt.title('T2')\n","    plt.subplot(133),plt.imshow(label[:,:,i,0]),plt.title('label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IxEAmrN0y3_P"},"source":["a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pyxh-_nYKLFj"},"source":["for i in range(128, 150):\n","    plt.figure(i+1, figsize=(24,24))\n","    plt.subplot(131),plt.imshow(a[0,35:110,80:155,i,0]),plt.title('T1')\n","    # plt.subplot(131),plt.imshow(imgT1[35:110,80:155,i,0]),plt.title('T1')\n","    plt.subplot(132),plt.imshow(x_trainT1[0,35:110,80:155,i,0]),plt.title('T2')\n","    # plt.subplot(133),plt.imshow(label[35:110,80:155,i,0]),plt.title('label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNi4IkR_6Cym"},"source":["path1 = sorted(glob.glob(\"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Validation/*.hdr\"))\n","path2 = sorted(glob.glob(\"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2017-Testing/*.hdr\"))\n","for i in range(len(path1)):\n","    ar1 = nib.load(path1[i]).get_fdata()\n","    ar2 = nib.load(path2[i]).get_fdata()\n","    k =np.linalg.norm(ar1-ar2)\n","    if k>0:\n","        print(k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8BbH-4DKMaS"},"source":["# path = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Validation/*.hdr\"\n","# path = \"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Training/*.hdr\"\n","\n","# for i in glob.glob(path):\n","#     ar = nib.load(i).get_fdata()\n","#     aug = CenterCrop(CROP_SIZE).apply(ar)\n","#     aug = aug[:,16:,16:,:]\n","#     # k = np.sum(aug[:,:16,:,:]) \n","#     k = np.sum(ar)- np.sum(aug)\n","#     if k > 0:\n","#         print(i+f\" with {k}\")"],"execution_count":null,"outputs":[]}]}