{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"eKLcUUwjEAog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633632435262,"user_tz":-420,"elapsed":101978,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"9029558c-69ef-43ce-8ef5-80e710dc0057"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# import zipfile\n","# with zipfile.ZipFile(\"/content/drive/MyDrive/iseg2019/dataISEG_np/train_patch32_stride8.zip\", 'r') as zip_ref:\n","#     zip_ref.extractall(\"data_train\")\n","# with zipfile.ZipFile(\"/content/drive/MyDrive/iseg2019/dataISEG_np/test_patch32_stride8.zip\", 'r') as zip_ref:\n","#     zip_ref.extractall(\"data_test\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"C21r7gQiGOFF"},"source":["from IPython.display import clear_output\n","import nibabel as nib\n","import glob \n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from fastprogress import master_bar, progress_bar\n","from torchvision import transforms\n","import torch.optim as optim\n","from itertools import product\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader,Dataset\n","import matplotlib.pyplot as plt\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","clear_output()\n","\n","def csv_log(filepath,**dict_save):\n","    header = list(dict_save.keys())\n","    isFile = os.path.isfile(filepath)\n","    with open(filepath, 'a', newline='') as csvfile:\n","        writer = csv.DictWriter(csvfile, fieldnames=header)\n","        if not isFile:\n","            writer.writeheader()\n","        writer.writerow(dict_save) \n","def extract_patches(arr, patch_shape=8, extraction_step=1):\n","    arr_ndim = arr.ndim\n","    patch_strides = arr.strides\n","\n","    slices = [slice(None, None, st) for st in extraction_step]\n","    indexing_strides = arr[tuple(slices)].strides\n","\n","    patch_indices_shape = ((np.array(arr.shape) - np.array(patch_shape)) //\n","                           np.array(extraction_step)) + 1\n","    \n","    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n","    strides = tuple(list(indexing_strides) + list(patch_strides))\n","    patches = np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n","    npatches = np.prod(patches.shape[:arr_ndim])\n","    return patches.reshape((npatches, ) + patch_shape)\n","\n","def reconstruct_volume_avg(patches, expected_shape, extraction_step = (1,8,8,8), num_class = 4):\n","    v_x, v_y, v_z = expected_shape\n","    p_x, p_y, p_z = patches.shape[2:]\n","    s_x, s_y, s_z = extraction_step[1:]# compute the dimensions of the patches array\n","    n_x = (v_x - p_x) // s_x + 1\n","    n_y = (v_y - p_y) // s_y + 1\n","    n_z = (v_z - p_z) // s_z + 1\n","\n","    vol = np.zeros((num_class, v_x, v_y, v_z))\n","    count = np.zeros((num_class, v_x, v_y, v_z))\n","\n","    for p, (i, j, k) in zip(patches, product(range(n_x), range(n_y), range(n_z))):\n","        vol[:, i*s_x:i*s_x+ p_x, j*s_y:j*s_y + p_y, k*s_z:k*s_z + p_z]  +=p\n","        count[:, i*s_x:i*s_x+ p_x, j*s_y:j*s_y + p_y, k*s_z:k*s_z + p_z] +=1\n","    return vol/count\n","\n","def min_max_preprocess(image, low_perc=1, high_perc=99):\n","    \"\"\"Main pre-processing function used for the challenge (seems to work the best).\n","    Remove outliers voxels first, then min-max scale.\n","    \"\"\"\n","    non_zeros = image > 0\n","    low, high = np.percentile(image[non_zeros], [low_perc, high_perc])\n","    image = np.clip(image, low, high)\n","    image = (image - low) / (high - low)\n","    return image\n","class AddNoise():\n","    def __init__(self, p):\n","        self.p = p\n","    def __call__(self, volume):\n","        if self.p > torch.rand(1):\n","            volume = volume * np.random.uniform(0.9, 1.1)\n","            std_per_channel = np.stack([np.std(volume[channel][volume[channel] > 0]) \\\n","                                        for channel in range(volume.shape[0])])\n","            noise = np.concatenate([np.random.normal(0, std * 0.1+1e-5, size=volume[:1].shape) \\\n","                            for std in std_per_channel], axis = 0)\n","            return np.clip(volume + noise, 0, 1)\n","# class RandomFlip():\n","#     def __init__(self, p):\n","#         self.p = p\n","#     def __call__(self, volume, mask):\n","#         if self.p > torch.rand(1):\n","            \n","\n","######################################################\n","PATCH_SIZE = (2,32,32,32)\n","EXTRACTION_STEP = (1,8,8,8)\n","NUM_CLASS = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLqYno7Qfj_H"},"source":["TRAIN_PATH = \"/content/data_train/*\"\n","TEST_PATH = \"/content/data_test/*\"\n","PSEUDO_PATH = \"/content/pseudo_data/*\"\n","class IsegLoader(Dataset):\n","    def __init__(self, train_path=TRAIN_PATH, test_path= TEST_PATH, \n","                 transform=None, typeData = \"train\"):\n","        list_testName = sorted(glob.glob(test_path))\n","        self.listName =  glob.glob(train_path) + glob.glob(PSEUDO_PATH) if typeData == \"train\" else list_testName\n","        self.transform = transform if typeData == \"train\" else None  # augment data bool\n","        self.typeData = typeData\n","\n","    def __len__(self):\n","        return len(self.listName)\n","    def __getitem__(self, idx):\n","        subject = np.load(self.listName[idx])\n","        volume, mask = subject[\"image\"], subject[\"mask\"]\n","    ####################### augmentation data ##############################\n","        # if self.transform:\n","        #     volume = self.transform(volume)\n","        return torch.from_numpy(volume), torch.from_numpy(mask)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"trmLSPr4_VXC"},"source":["# train_dataset = DataLoader(IsegLoader(), batch_size=16, \n","#                         shuffle=True, num_workers=2, \n","#                         drop_last=True, prefetch_factor = 8)\n","# test_dataset = DataLoader(IsegLoader(typeData=\"test\"), batch_size=64,\n","#                           num_workers=2, prefetch_factor=32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6UaVEOSm8eF"},"source":["# train_data = IsegLoader(transform = AddNoise(p = 0.2)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aiq5wXN5H0RJ"},"source":["# listOfT1_train = glob.glob(\"/content/drive/MyDrive/iseg2019/dataISEG/iSeg-2019-Training/*T1.hdr\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MoNFlL0RJ2ke"},"source":["# !mkdir train_pt\n","# !mkdir test_pt\n","# count_train = 0\n","# count_test = 0\n","# SAVE_TEST_PATH = \"./test_pt/\"\n","# SAVE_TRAIN_PATH = \"./train_pt/\"\n","# for i in range(len(listOfT1_train)):\n","#     print(\"\\r read in: \", i+1,\"th volume\", end=\"\")\n","#     t1 = np.transpose(nib.load(listOfT1_train[i]).get_fdata(), (-1,0,1,2))\n","#     t2 = np.transpose(nib.load(listOfT1_train[i].replace(\"T1\", \"T2\")).get_fdata(), (-1,0,1,2))\n","#     seg = np.transpose(nib.load(listOfT1_train[i].replace(\"T1\", \"label\")).get_fdata(), (-1,0,1,2))\n","#     t1 = min_max_preprocess(t1)\n","#     t2 = min_max_preprocess(t2)\n","    \n","#     t1 = np.asarray(t1, np.float32)\n","#     t2 = np.asarray(t2, np.float32)\n","#     seg = np.asarray(seg, np.int64)\n","\n","#     inputs = np.concatenate([t1, t2], axis= 0)\n","\n","#     label_patch = extract_patches(seg, (1,*PATCH_SIZE[1:]), EXTRACTION_STEP)\n","#     valid_index = np.where(np.sum(label_patch, axis=(1, 2, 3, 4)) != 0)\n","#     y = label_patch[valid_index]\n","#     del label_patch, seg\n","\n","#     input_patches = extract_patches(inputs, PATCH_SIZE, EXTRACTION_STEP)\n","#     data_input = input_patches[valid_index]\n","#     del input_patches, inputs\n","\n","#     x_train, x_test, y_train, y_test = train_test_split(data_input, y, test_size=0.1)\n","#     del data_input, y\n","#     for j in range(x_train.shape[0]):\n","#         print(\"\\rsave \",count_train,\"th volume for train\", end=\"\")      \n","#         np.savez_compressed(SAVE_TRAIN_PATH+\"iseg_\"+str(count_train), \n","#                                 image=x_train[j], mask=y_train[j]) \n","#         count_train += 1 \n","\n","#     for j in range(x_test.shape[0]):\n","#         print(\"\\rsave \",count_test,\"th volume for test\", end=\"\")      \n","#         np.savez_compressed(SAVE_TEST_PATH+\"iseg_\"+str(count_test), \n","#                                 image=x_test[j], mask=y_test[j]) \n","#         count_test += 1 \n","#     del x_train, x_test, y_train, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6N-qMaDU3VX","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1633635317598,"user_tz":-420,"elapsed":102114,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"9d6fcd7c-c734-467f-f086-8236d1691c5d"},"source":["# import shutil\n","# shutil.make_archive(\"/content/drive/MyDrive/iseg2019/dataISEG_np/train_pt\",\n","#                     \"zip\",\"/content/train_pt\") \n","# shutil.make_archive(\"/content/drive/MyDrive/iseg2019/dataISEG_np/test_pt\",\n","#                     \"zip\",\"/content/test_pt\") "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/iseg2019/dataISEG_np/test_pt.zip'"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0haH_5FWHEee","executionInfo":{"status":"ok","timestamp":1633635214354,"user_tz":-420,"elapsed":749633,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"2d2c8c0a-3e41-4c44-a427-aec3624f096f"},"source":["# path_train = glob.glob(\"/content/data_train/*\")\n","# path_test =  glob.glob(\"/content/data_test/*\")\n","# from tqdm import tqdm\n","# SAVE_TEST_PATH = \"./test_pt/\"\n","# SAVE_TRAIN_PATH = \"./train_pt/\"\n","# count_train = 0\n","# count_test = 0\n","# for i in tqdm(path_train):\n","#     subject = np.load(i)\n","#     volume, mask = subject[\"image\"], subject[\"mask\"]\n","#     volume =  np.asarray(volume.transpose((-1,0,1,2)), np.float32)\n","#     mask = np.asarray(mask.transpose((-1,0,1,2)), np.int64)\n","#     np.savez_compressed(SAVE_TRAIN_PATH+\"iseg_\"+str(count_train), \n","#                                 image=volume, mask=mask) \n","#     count_train += 1 \n","# for i in tqdm(path_test):\n","#     subject = np.load(i)\n","#     volume, mask = subject[\"image\"], subject[\"mask\"]\n","#     volume =  np.asarray(volume.transpose((-1,0,1,2)), np.float32)\n","#     mask = np.asarray(mask.transpose((-1,0,1,2)), np.int64)\n","#     np.savez_compressed(SAVE_TEST_PATH+\"iseg_\"+str(count_test), \n","#                                 image=volume, mask=mask) \n","#     count_test += 1 "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 35732/35732 [11:16<00:00, 52.81it/s]\n","100%|██████████| 3977/3977 [01:12<00:00, 54.63it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"WGZcsP2jQScb"},"source":["# import time\n","# count = 1\n","# t1 = time.time()\n","# for _ in train_dataset:\n","#     print(\"\\r read\",count, end=\"\")\n","#     count+=1\n","#     time.sleep(0.2)\n","# print(\"\\n\", time.time()-t1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CZk2ronGxA38"},"source":["# x, y = next(iter(train_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRTLqTKmKpdj"},"source":["# patches = volume\n","# seg_patches = mask\n","# for i in range(32):\n","#     plt.figure(i+1, figsize=(12,12))\n","#     plt.subplot(131),plt.imshow(patches[0,:,:,i]),plt.title('T1')\n","#     plt.subplot(132),plt.imshow(patches[1,:,:,i]),plt.title('T2')\n","#     plt.subplot(133),plt.imshow(seg_patches[0,:,:,i]),plt.title('seg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDaXFr94eodZ"},"source":["##loss"]},{"cell_type":"code","metadata":{"id":"lpy56sQyeuvg"},"source":["class SemiActiveLoss(nn.Module):\n","    def __init__(self, device, alpha =1e-9, beta = 1e-1, lamda = 1e-3):\n","        super().__init__()\n","        self.device = device\n","        self.alpha = alpha\n","        self.beta = beta     \n","        self.lamda = lamda \n","    def LevelsetLoss(self, image, y_pred, kernel_size=5, smooth=1e-5):\n","        kernel = torch.ones(1, y_pred.size(1), kernel_size, kernel_size, kernel_size, device=self.device) / kernel_size**3\n","        padding = kernel_size //2\n","        lossRegion = 0.0\n","        y_pred_fuzzy = y_pred\n","        for ich in range(image.size(1)):\n","            target_ = image[:,ich:ich+1] \n","            pcentroid_local = F.conv3d(target_ * y_pred_fuzzy + smooth, kernel, padding = padding) \\\n","                                / F.conv3d(y_pred_fuzzy + smooth, kernel, padding = padding)\n","            plevel_local = target_ - pcentroid_local\n","            loss_local = plevel_local * plevel_local * y_pred_fuzzy\n","\n","            pcentroid_global = torch.sum(target_ * y_pred_fuzzy, dim=(2,3,4),keepdim=True) \\\n","                                / torch.sum(y_pred_fuzzy+smooth, dim=(2,3,4),keepdim = True)   \n","            plevel_global = target_ - pcentroid_global\n","            loss_global = plevel_global * plevel_global * y_pred_fuzzy\n","\n","            lossRegion += torch.sum(loss_local) + self.beta * torch.sum(loss_global)\n","        return lossRegion \n","    def GradientLoss(self, y_pred, penalty = \"l1\"):\n","        dH = torch.abs(y_pred[...,1:] - y_pred[...,:-1])\n","        dW = torch.abs(y_pred[:,:,:,1:] - y_pred[:,:,:,:-1])\n","        dD = torch.abs(y_pred[:,:,1:] - y_pred[:,:,:-1])\n","        if penalty == \"l2\":\n","            dH = dH * dH\n","            dW = dW * dW\n","            dD = dD * dD\n","        loss =  torch.sum(dH) +  torch.sum(dW)+ torch.sum(dD)\n","        return loss\n","    def ActiveContourLoss(self, y_true, y_pred, smooth=1e-5):   \n","        dim = (1,2,3,4)\n","        yTrueOnehot = torch.zeros(y_true.size(0), NUM_CLASS, y_true.size(2), y_true.size(3), y_true.size(4), device=self.device)\n","        yTrueOnehot = torch.scatter(yTrueOnehot, 1, y_true, 1)[:,1:]\n","        y_pred = y_pred[:,1:]\n","\n","        active = - torch.log(1-y_pred+smooth) * (1-yTrueOnehot) - torch.log(y_pred+smooth) * yTrueOnehot\n","        loss = torch.sum(active, dim = dim) / torch.sum(yTrueOnehot + y_pred- yTrueOnehot * y_pred +smooth, dim = dim)\n","        return torch.mean(loss)\n","\n","    def forward(self, image, y_true, y_pred):\n","        active = self.ActiveContourLoss(y_true, y_pred)\n","        levelset =  self.LevelsetLoss(image, y_pred)\n","        length = self.GradientLoss(y_pred)\n","        return active + self.alpha * (levelset + self.lamda * length) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DnPx9nmRfEyp"},"source":["##metrics"]},{"cell_type":"code","metadata":{"id":"IGrw4VZPfGQ3"},"source":["def dice_CSF(y_true, y_pred, smooth = 1.0):\n","    output_standard = torch.argmax(y_pred, dim=1, keepdim = True)\n","    output_CSF = torch.where(output_standard == 1, 1, 0)\n","    label_CSF = torch.where(y_true == 1, 1, 0)\n","\n","    intersection = torch.sum(label_CSF * output_CSF, dim=[1,2,3,4])\n","    union = torch.sum(label_CSF, dim=[1,2,3,4]) + torch.sum(output_CSF, dim=[1,2,3,4])\n","    return torch.mean((2. * intersection + smooth) / (union + smooth), dim=0)\n","\n","def dice_GM(y_true, y_pred, smooth = 1.0):\n","    output_standard = torch.argmax(y_pred, dim=1, keepdim = True)\n","    output_GM = torch.where(output_standard == 2, 1.0, 0.0)\n","    label_GM = torch.where(y_true == 2, 1.0, 0.0)\n","\n","    intersection = torch.sum(label_GM * output_GM, dim=[1,2,3,4])\n","    union = torch.sum(label_GM, dim=[1,2,3,4]) + torch.sum(output_GM, dim=[1,2,3,4])\n","    return torch.mean((2. * intersection + smooth) / (union + smooth), dim=0)\n","\n","def dice_WM(y_true, y_pred, smooth = 1.0):\n","    output_standard = torch.argmax(y_pred, dim=1,keepdim = True)\n","    output_WM = torch.where(output_standard == 3, 1.0, 0.0)\n","    label_WM = torch.where(y_true == 3, 1.0, 0.0)\n","\n","    intersection = torch.sum(label_WM * output_WM, dim=[1,2,3,4])\n","    union = torch.sum(label_WM, dim=[1,2,3,4]) + torch.sum(output_WM, dim=[1,2,3,4])\n","    return torch.mean((2. * intersection + smooth) / (union + smooth), dim=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B65eOb4VOE4G"},"source":["##optimizer"]},{"cell_type":"code","metadata":{"id":"fYPf1-J-OGl8"},"source":["import math\n","import torch\n","from torch.optim.optimizer import Optimizer\n","\n","\n","class Nadam(Optimizer):\n","    \"\"\"Implements Nadam algorithm (a variant of Adam based on Nesterov momentum).\n","    It has been proposed in `Incorporating Nesterov Momentum into Adam`__.\n","    Arguments:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float, optional): learning rate (default: 2e-3)\n","        betas (Tuple[float, float], optional): coefficients used for computing\n","            running averages of gradient and its square\n","        eps (float, optional): term added to the denominator to improve\n","            numerical stability (default: 1e-8)\n","        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n","        schedule_decay (float, optional): momentum schedule decay (default: 4e-3)\n","    __ http://cs229.stanford.edu/proj2015/054_report.pdf\n","    __ http://www.cs.toronto.edu/~fritz/absps/momentum.pdf\n","        Originally taken from: https://github.com/pytorch/pytorch/pull/1408\n","        NOTE: Has potential issues but does work well on some problems.\n","    \"\"\"\n","\n","    def __init__(self, params, lr=2e-3, betas=(0.9, 0.999), eps=1e-8,\n","                 weight_decay=0, schedule_decay=4e-3):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        defaults = dict(\n","            lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, schedule_decay=schedule_decay)\n","        super(Nadam, self).__init__(params, defaults)\n","\n","    @torch.no_grad()\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            with torch.enable_grad():\n","                loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['m_schedule'] = 1.\n","                    state['exp_avg'] = torch.zeros_like(p)\n","                    state['exp_avg_sq'] = torch.zeros_like(p)\n","\n","                # Warming momentum schedule\n","                m_schedule = state['m_schedule']\n","                schedule_decay = group['schedule_decay']\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","                eps = group['eps']\n","                state['step'] += 1\n","                t = state['step']\n","                bias_correction2 = 1 - beta2 ** t\n","\n","                if group['weight_decay'] != 0:\n","                    grad = grad.add(p, alpha=group['weight_decay'])\n","\n","                momentum_cache_t = beta1 * (1. - 0.5 * (0.96 ** (t * schedule_decay)))\n","                momentum_cache_t_1 = beta1 * (1. - 0.5 * (0.96 ** ((t + 1) * schedule_decay)))\n","                m_schedule_new = m_schedule * momentum_cache_t\n","                m_schedule_next = m_schedule * momentum_cache_t * momentum_cache_t_1\n","                state['m_schedule'] = m_schedule_new\n","\n","                # Decay the first and second moment running average coefficient\n","                exp_avg.mul_(beta1).add_(grad, alpha=1. - beta1)\n","                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1. - beta2)\n","\n","                denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n","                p.addcdiv_(grad, denom, value=-group['lr'] * (1. - momentum_cache_t) / (1. - m_schedule_new))\n","                p.addcdiv_(exp_avg, denom, value=-group['lr'] * momentum_cache_t_1 / (1. - m_schedule_next))\n","\n","        return loss"],"execution_count":null,"outputs":[]}]}